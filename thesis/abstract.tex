\begin{abstract}

The author and colleagues previously developed an agent for Ms~Pac-Man using Monte Carlo tree search, which runs hundreds of simulated games in order to reach a decision about which move to play, in real time.  During these simulated games, a model of ghost behaviour is used: it was found that when this model happens to match the opponent ghost team, the agent performs well; but when the model and opponent do not match, the agents performance is significantly reduced as its decisions are based on mistaken assumptions.  The aim of this project therefore is to develop a ghost model to use during the simulations that learns by observing the opponent, in order to more accurately model the opponent and improve the score.  The learning algorithm chosen employs neural networks.  Hundreds of games were played to test the effectiveness of the approach with the help of an experiment server, developed for the project, to distribute the games over many machines.  The results show that overall, the learning ghost model decreases performance, but certain cases show a significant improvement, and the learning aspect is demonstrated.  Another important conclusion is that neural networks may not have been the best choice, and the report gives various suggestions for further work.

\end{abstract}
