\chapter{Related work}
\label{ch:related}


\section{The Ms~Pac-Man environment}
The original Pac-Man was an arcade game developed by Toru Iwatani, a Japanese games designer working for Namco Company, in 1980 \cite{Samothrakis2011}.  It became hugely successful due to its wide appeal and a number of spin-offs were created.  One of these was Ms~Pac-Man, which was initially created unofficially before being sold to Midway Games, who distributed Namco games in North America.

The original game features a pizza-shaped protagonist "Pac-Man" which the player must direct around a maze consuming "pills" and occasionally fruit when it becomes available, whilst avoiding the four ghosts ("Pinky", "Inky", "Blinky" and "Clyde") which attempt to eat Pac-Man.  If they succeed, Pac-Man loses a life.  There are four "power pills" in the maze: if Pac-Man eats one, all the ghosts turn blue and become edible.  Eating as many ghosts as possible in this state confers a significant advantage, as not only is the player rewarded with a number of points upon eating a ghost, the number of points on offer for a ghost doubles with each one eaten.  Starting at 200 for the first ghost, it increases to 400, 800, and 1600 for each consecutive ghost eaten whilst the same power pill is still active.  Thus, the total score available from a power pill is 3050 (50 for the power pill itself, and the sum of the scores mentioned above) - this is in contrast to only 10 points for each regular pill consumed.  Once all the pills in a maze have been cleared, the next level is reached.  Ghosts stay edible for decreasing amounts of time in each subsequent level, making it harder both to score points and to stay alive.

The original Pac-Man featured deterministic ghost behaviour and so it is possible to exploit known patterns of behaviour to learn how to play a given level in such a way that the maximum score for that level is always achieved.  However, Ms~Pac-Man features more sophisticated ghost behaviour which involves a level of non-determinism, making it much more difficult to play.  The other notable difference between the two games is that the latter has four levels instead of just one; there are other minor cosmetic differences such as the renaming of the orange ghost previously known as "Clyde" to "Sue", and the addition of a red bow and lipstick to the Pac-Man character.

Ms~Pac-Man is now more than thirty years old, a considerable time in the technology arena, and much more sophisticated games exist for the exponentially faster hardware available today; however, it remains useful to artificial intelligence research.  Much work has been done in creating game-playing agents for a wide range of games including chess, checkers, Go, and even Jeapordy, and these agents are often at least as good as human champions.  However, the task environment \todo{Read Russell and Norvig} of Ms~Pac-Man presents several interesting challenges.

Unlike the games mentioned above, the Ms~Pac-Man environment is \emph{dynamic} rather than \emph{static}: whilst in chess the state of the game remains fixed between moves, the state in Ms~Pac-Man is continuously changing, even if the agent is not making any moves.  Additionally, rather than being afforded several minutes to deliberate, the agent must post a move relatively frequently (every 40~ms in the framework mentioned below).  Thus, the environment is also \emph{quasi-continuous} as opposed to being completely \emph{discrete} like board games.

Board games also tend overwhelmingly to be \emph{deterministic}, meaning that the results of a move can be completely and exactly determined by the agent.  In contrast, the Ms~Pac-Man environment is \emph{stochastic}: the ghosts incorporate random behaviour and therefore cannot be completely predicted.  Further complicating the problem of predicting the state of the game after a move is the fact that both Ms~Pac-Man and the ghosts make moves \emph{simultaneously} rather than taking turns as in the majority of board games.

However, the player does have knowledge of the whole game state available to them when making a decision, an attribute shared with traditional board games.  Similarly, all actions available to the player in a given state can be fully known and enumerated.

It can be seen that although Ms~Pac-Man is a seemingly simple, having a trivial objective and few rules, it is perhaps deceptively so, and certain aspects of the task environment greatly increase the complexity of developing an effective agent.  Accordingly, the performance of artificial agents falls somewhat short of the scores achieved by human players.

The usefulness of Ms~Pac-Man to the field of artificial intelligence has previously been recognised and there exists a reasonable amount of research on the subject to date.  This has been encouraged by the creation of various frameworks and competitions to facilitate the development of artificial agents.  The original code is closed source and not designed to run on modern computers, and thus frameworks have had to be written to enable custom agent code to interface with the game.  Various authors \cite{Lucas2005;Koza1992} have implemented their own simulated versions of the game, sometimes with quite different behaviour to the original game. \cite{Robles2009} also implemented their own version, as well as providing a framework which uses a screen capturing technique to allow the agent to extract information out of the original game running in an emulator.  They demonstrated that their simulator framework and the screen capture framework were roughly equivalent.

It is argued that exact equivalence to the real game is not important however, as the main motivation of such research is not necessarily to write an agent capable of playing the real game well (no its own, a goal of somewhat questionable utility); rather it is to write an agent capable of dealing with the kind of complexities present in a game such as Ms~Pac-Man.  As long as the simulated task environment is not significantly different to the real one as described above, the same benefits may be derived from the research.  It is nevertheless important to note that scores obtained by agents under different simulators cannot readily be compared.

The framework used in this work, the aforementioned simulator framework, was developed at the University of Essex (\cite{Robles2009}) and used to host various competitions such as at the 2009 IEEE Conference on Computational Intelligence and Games (CIG 2012\footnote{\url{http://geneura.ugr.es/cig2012/}}) and at the IEEE World Congress on Computational Intelligence (WCCI 2012\footnote{\url{http://www.ieee-wcci2012.org/}}).  The framework is written in Java and closely replicates the original game, with a few notable exceptions:

\begin{itemize}
\item Ms~Pac-Man and the ghosts travel at the same speed, unless a power-pill is active, in which case Ms~Pac-Man can move faster than the ghosts.  Unlike the original, Ms~Pac-Man does not slow down when eating pills.
\item In the original, ghosts slow down in the "tunnels" at the side of the screen, providing an opportunity to put some distance between Ms~Pac-Man and a pursuing ghost.  This is not the case in the simulator.
\item The simulator does not include the bonus fruit.
\item The behaviour of the ghosts can be determined by any custom ghost controller class.  This is a significant difference which makes the task not only much harder, but arguably much more interesting, as tactics which are effective against one ghost "team" may not be effective against another.  The competitions generally feature user-submitted ghost teams as well as Ms~Pac-Man controllers and therefore it is not possible to know in advance what ghost teams the agent should be able to play against.  This point is the main reason behind this paper.
\end{itemize}

\section{Monte Carlo tree search}


\section{Notable Ms~Pac-Man game-playing agents}

